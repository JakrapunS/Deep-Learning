{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"COSC2779LabExercises_W5.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPT21mfJr86kHDrEj7HhAic"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Th5rx_UqpqbA"},"source":["---\n","# <div align=\"center\"><font color='blue'>  </font></div>\n","# <div align=\"center\"><font color='blue'> COSC 2779 | Deep Learning  </font></div>\n","## <div align=\"center\"> <font color='blue'> Week 5 Lab Exercises: **Data loader and Augmentation**</font></div>\n","---"]},{"cell_type":"markdown","metadata":{"id":"EEnjLoZvAhZP"},"source":["# Introduction\n","\n","This lab is aimed at understanding how to write your own data loader and learn the importance of data augmentation. During this lab you will:\n","\n","- Learn to do data augmentation\n","- Explore different data loading mechanisms in TensorFlow\n","- Implement CNN\n","- Write your own dataloader\n","- Explore more functionality in TensorBoard\n","\n","\n","![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)  This notebook is designed to run on Google Colab. If you like to run this on your local machine, make sure that you have installed TensorFlow version 2.0. "]},{"cell_type":"markdown","metadata":{"id":"-9Ia9Ef2FPPD"},"source":["## Setting up the Notebook\n","\n","Lets first load the packages we need."]},{"cell_type":"code","metadata":{"id":"XMWFpQBMFPcP"},"source":["import tensorflow as tf\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow_datasets as tfds\n","import pathlib\n","import shutil\n","import tempfile\n","\n","from  IPython import display\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lzgwsi6hFt-x"},"source":["We can use the tensor board to view the learning curves. Lets first set it up.\n","\n"]},{"cell_type":"code","metadata":{"id":"mAoWKwpUFuMB"},"source":["logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n","shutil.rmtree(logdir, ignore_errors=True)\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Open an embedded TensorBoard viewer\n","%tensorboard --logdir {logdir}/models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FqU66bsNF5wp"},"source":["We can also write our own function to plot the models training history ones training has completed."]},{"cell_type":"code","metadata":{"id":"2AuNxHysF54Y"},"source":["from itertools import cycle\n","def plotter(history_hold, metric = 'binary_crossentropy', ylim=[0.0, 1.0]):\n","  cycol = cycle('bgrcmk')\n","  for name, item in history_hold.items():\n","    y_train = item.history[metric]\n","    y_val = item.history['val_' + metric]\n","    x_train = np.arange(0,len(y_val))\n","\n","    c=next(cycol)\n","\n","    plt.plot(x_train, y_train, c+'-', label=name+'_train')\n","    plt.plot(x_train, y_val, c+'--', label=name+'_val')\n","\n","  plt.legend()\n","  plt.xlim([1, max(plt.xlim())])\n","  plt.ylim(ylim)\n","  plt.xlabel('Epoch')\n","  plt.ylabel(metric)\n","  plt.grid(True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3oyYu0qqBEKJ"},"source":["## Data Augmentation\n","\n","Image Augmentation is the process of generating new images for training our deep learning model. These new images are generated using the existing training images and hence we don’t have to collect them manually.\n","\n","Data augmentation is a common technique to improve results and avoid overfitting in neural networks.\n","\n","Common augmentation techniques used in deep learning are discussed in lecture 4. To understand the importance of augmentation let’s train a simple model with and without augmentation and observe.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rmbepEAfwgtb"},"source":["### Simple Example\n","We will use the MNIST dataset for this task."]},{"cell_type":"code","metadata":{"id":"ROC6VskZAZMp"},"source":["dataset, info =  tfds.load('mnist', as_supervised=True, with_info=True)\n","train_dataset, test_dataset = dataset['train'], dataset['test']\n","\n","num_train_examples= info.splits['train'].num_examples"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AVPdHnn0GKIV"},"source":["Write a function to augment the images. Here we first convert the images to range [0,1] and then do the following augmetnations:\n","- resize the image to 34 x 34 by padding\n","- Crop it back to 28 x 28. The combined effect would be translation of the image in both x, y directions.\n","- Change the brightness of the image pixels randomly."]},{"cell_type":"code","metadata":{"id":"XNA-hr4eGKSL"},"source":["def convert(image, label):\n","  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n","  return image, label\n","\n","def augment(image,label):\n","  image,label = convert(image, label)\n","  image = tf.image.resize_with_crop_or_pad(image, 34, 34) # Add 6 pixels of padding\n","  image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28\n","  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n","\n","  return image,label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4VbS_09HHDr"},"source":["Next step is to apply the above augmentations to the training dataset and create augmented datasets. Here we are going to limit the data to 2048 instances to highlight the affect of augmentation in preventing overfitting. the original MNIST dataset has many examples and it is unlikely to overfit."]},{"cell_type":"code","metadata":{"id":"fa0KUF24HHOl"},"source":["BATCH_SIZE = 64\n","# Only use a subset of the data so it's easier to overfit, for this tutorial\n","NUM_EXAMPLES = 2048\n","\n","augmented_train_batches = (\n","    train_dataset\n","    # Only train on a subset, so you can quickly see the effect.\n","    .take(NUM_EXAMPLES)\n","    .cache()\n","    .shuffle(num_train_examples//4)\n","    # The augmentation is added here.\n","    .map(augment, num_parallel_calls=AUTOTUNE)\n","    .batch(BATCH_SIZE)\n","    .prefetch(AUTOTUNE)\n",") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FwKKXt-iH-c_"},"source":["For comparisons we will generate a non augmented dataset as well."]},{"cell_type":"code","metadata":{"id":"K3AIGe-aH9tM"},"source":["non_augmented_train_batches = (\n","    train_dataset\n","    # Only train on a subset, so you can quickly see the effect.\n","    .take(NUM_EXAMPLES)\n","    .cache()\n","    .shuffle(num_train_examples//4)\n","    # No augmentation.\n","    .map(convert, num_parallel_calls=AUTOTUNE)\n","    .batch(BATCH_SIZE)\n","    .prefetch(AUTOTUNE)\n",") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEjysjbeIGvZ"},"source":["Validation batches are not usually augmented."]},{"cell_type":"code","metadata":{"id":"Wep6gt91IGHf"},"source":["validation_batches = (\n","    test_dataset\n","    .map(convert, num_parallel_calls=AUTOTUNE)\n","    .batch(BATCH_SIZE)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ZTBIkQ0IRAf"},"source":["Create callbacks for tensorboard. `histogram_freq=1` writes the histogram of weights while training. This enables us to look at the evolution of weights during the training process. "]},{"cell_type":"code","metadata":{"id":"Uu0qrjERIi0O"},"source":["m_histories = {}\n","\n","def get_callbacks(name):\n","  return [\n","    tf.keras.callbacks.TensorBoard(logdir/name, histogram_freq=1),\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQ54_iVnIkTx"},"source":["<font color='red'>**TODO:** Create a model with two fully connected hidden layers with 4096 `ReLU` units. </font> \n","\n","Train the model without augmentation"]},{"cell_type":"code","metadata":{"id":"Xpa7tI-gIkcY"},"source":["model_no_aug = tf.keras.Sequential([\n","      # Complete the model\n","  ])\n","model_no_aug.compile(optimizer = 'adam',\n","              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=[tf.losses.SparseCategoricalCrossentropy(from_logits=True, name='SparseCategoricalCrossentropy'), 'accuracy'])\n","\n","m_histories['No_augmentation'] = model_no_aug.fit(non_augmented_train_batches, epochs=50, validation_data=validation_batches, verbose=0, callbacks=get_callbacks('models/noAug'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBK977YkJugD"},"source":["<font color='red'>**TODO:** Create a model with two fully connected hidden layers with 4096 `ReLU` units. Same model as above. </font> \n","\n","Train the model with augmentation"]},{"cell_type":"code","metadata":{"id":"gsHer_qtJuol"},"source":["model_with_aug = tf.keras.Sequential([\n","      # Complete the model\n","  ])\n","model_with_aug.compile(optimizer = 'adam',\n","              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=[tf.losses.SparseCategoricalCrossentropy(from_logits=True, name='SparseCategoricalCrossentropy'), 'accuracy'])\n","\n","m_histories['With_augmentation'] = model_with_aug.fit(augmented_train_batches, epochs=50, validation_data=validation_batches, verbose=0, callbacks=get_callbacks('models/Aug'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U_9grwhOSgLC"},"source":["Plot the results"]},{"cell_type":"code","metadata":{"id":"B-Gi8jolJ94J"},"source":["plotter(m_histories, ylim=[0.0, 1.1], metric = 'SparseCategoricalCrossentropy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZWbCk1zLf29"},"source":["plotter(m_histories, ylim=[0.0, 1.1], metric = 'accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CybEz4BcwbMr"},"source":["**Did you observes overfitting in the model trained without augmentation?**\n","\n","**Has augmentation prevented overfitting?**\n","\n","**What are the other types of augmentation you can use for this task?**\n","\n","**Explore other available options in TensorFlow Image Documentation](https://www.tensorflow.org/api_docs/python/tf/image)**"]},{"cell_type":"markdown","metadata":{"id":"eho8VN0QUGGu"},"source":["### Detailed Example\n","\n","In this demo we will use CNN to predict the orientation of a face in a 32 by 32 pixel image. The data set used is from: [Chapter 4 of Machine Learning book by Tom Mitchell](http://www.cs.cmu.edu/~tom/faces.html)\n","\n","The faces of 20 different people are captured at 4 orientations: Left, Right, Up, Straight. Images from each individual is in a separate folder and the label (orientation) for a specific image is given by the image name.  `glickman_up_neutral_sunglasses.pgm -> up`"]},{"cell_type":"code","metadata":{"id":"I9APudR9UJ29"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","print(\"Tensorflow version is: \", tf.__version__)\n","assert tf.__version__[0] == '2'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVNUJKF-EzIG"},"source":["The image names and the labels are converted to CSV files and are available on canvas. Upload the data files to the google drive and then get it to the colab instance using the commands below."]},{"cell_type":"code","metadata":{"id":"YiKjh7phXjHi"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cp /content/drive/'My Drive'/COSC2779/COSC2779lab5/faces_TM.zip .\n","!unzip -q -o faces_TM.zip\n","!rm faces_TM.zip\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJ3MRnfRF8EX"},"source":["Load the dataset names and labels into pandas data frames. \n","\n","**When developing machine learning models one would usually do some data exploration at this point. Check how the images look like and identify the properties of the task. This information should be used to justify your design choices**"]},{"cell_type":"code","metadata":{"id":"S7PLmHC8YNIp"},"source":["import pandas as pd\n","import numpy as np\n","\n","train_data_df = pd.read_csv('./faces_TM/TrainData_faces.csv')\n","val_data_df = pd.read_csv('./faces_TM/ValData_faces.csv')\n","train_data_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvX9pg1zGnsx"},"source":["We can now read the data and organise them to a tensoflow dataset. You could  use the data generators to directly train the model. However since We like to use the same code structure from the previous simple example, the data is organised to a dataset. "]},{"cell_type":"code","metadata":{"id":"TwASRQDLYePe"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","BATCH_SIZE = 16\n","\n","def make_train_generator():\n","    train_datagen = ImageDataGenerator(data_format='channels_last')\n","    train_generator = train_datagen.flow_from_dataframe(\n","        dataframe=train_data_df,\n","        directory='./',\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        target_size=(32, 32),\n","        batch_size=1,\n","        color_mode=\"grayscale\",\n","        shuffle=False,\n","        class_mode='categorical')\n","    return train_generator\n","\n","def make_val_generator():\n","    datagen = ImageDataGenerator(data_format='channels_last')\n","    generator = datagen.flow_from_dataframe(\n","        dataframe=val_data_df,\n","        directory='./',\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        target_size=(32, 32),\n","        batch_size=1,\n","        color_mode=\"grayscale\",\n","        shuffle=False,\n","        class_mode='categorical')\n","    return generator\n","\n","train_dataset = tf.data.Dataset.from_generator(make_train_generator,output_types=(tf.float32, tf.float32), output_shapes=([1,32,32,1], [1,4]))\n","vaidation_dataset = tf.data.Dataset.from_generator(make_val_generator,output_types=(tf.float32, tf.float32), output_shapes=([1,32,32,1], [1,4]))\n","\n","VAL_DATA_LEN = 155\n","TRAIN_DATA_LEN = 469"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hY86Kv7iHJSt"},"source":["Print the shapes of the output tensor to check if the dataset generation is working. "]},{"cell_type":"code","metadata":{"id":"erL-1-uunMQe"},"source":["for image, label in train_dataset.take(5):\n","  print(image.shape, label.shape)\n","\n","for image, label in vaidation_dataset.take(5):\n","  print(image.shape, label.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VCm8QpAcHZ-P"},"source":["Write a function to augment the images. Here we first convert the image to range [0,1] and then do the following augmentations:\n","- resize the image to 34 x 34 by padding\n","- Rotate in the range [0,15] degrees\n","- Crop it back to 28 x 28. the combined effect would be translation of the image in both x, y directions.\n","- Change the brightness of the image pixels randomly."]},{"cell_type":"code","metadata":{"id":"78BQLluqzeAX"},"source":["!pip install tfa-nightly"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFXZLKFiYlGY"},"source":["import tensorflow_addons as tfa\n","import numpy as np \n","\n","@tf.function\n","def rotate_tf(image,ang_deg=15):\n","    \n","    random_angles = tf.random.uniform(shape = (), minval = -np.deg2rad(ang_deg), maxval = np.deg2rad(ang_deg))\n","    return tfa.image.rotate(image,random_angles)\n","\n","def convert(image, label):\n","  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n","  image = image[0,:]\n","  label = label[0,:]\n","  return image, label\n","\n","def augment(image,label):\n","  image,label = convert(image, label)\n","  image = tf.image.resize_with_crop_or_pad(image, 37, 37) # Add 5 pixels of padding\n","  image = rotate_tf(image, 5) # Rorate in the range [0,10]\n","  image = tf.image.random_crop(image, size=[32, 32, 1]) # Random crop back to 28x28\n","  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n","\n","  return image,label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OgvBC3d4HkCp"},"source":["Next step is to apply the above augmentations to the training dataset and create augmented datasets."]},{"cell_type":"code","metadata":{"id":"Fb8fgilAfa3e"},"source":["augmented_train_batches = train_dataset.take(TRAIN_DATA_LEN).cache()\n","augmented_train_batches = augmented_train_batches.shuffle(TRAIN_DATA_LEN).map(augment, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWXJxahDiB8y"},"source":["non_augmented_train_batches = train_dataset.take(TRAIN_DATA_LEN).cache()\n","non_augmented_train_batches = non_augmented_train_batches.shuffle(TRAIN_DATA_LEN).map(convert, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CtSbxnPiLRS"},"source":["validation_batches = vaidation_dataset.take(VAL_DATA_LEN).cache()\n","validation_batches =validation_batches.map(convert, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0T_sTbcQHtio"},"source":["Setup callback for tensorboard"]},{"cell_type":"code","metadata":{"id":"4V4f7qLviWf5"},"source":["m_histories = {}\n","\n","def get_callbacks(name):\n","  return [\n","    tf.keras.callbacks.TensorBoard(logdir/name),\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3zhfT4qpHwnX"},"source":["Write a function to create a CNN model. This model has several conv+pooling layers followed by a MLP classifier. L2 regularisation and dropout is also employed. Note that this function is not optimised for this task. **You are encouraged to find the best model as a self study exercise.**  "]},{"cell_type":"code","metadata":{"id":"lhMfTzMSioyy"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Lambda, Input\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n","from tensorflow.keras.metrics import categorical_accuracy\n","from tensorflow.keras import regularizers, optimizers\n","\n","def get_model():\n","  model_cnn = Sequential()\n","\n","  # input\n","  model_cnn.add(Input(shape=(32, 32, 1)))\n","\n","  # Conv Layer 1\n","  model_cnn.add(Conv2D(32, (3, 3),kernel_regularizer=regularizers.l2(0.001)))\n","  model_cnn.add(Activation('relu'))\n","  model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  # Conv Layer 2 (no pooling)\n","  model_cnn.add(Conv2D(32, (3, 3),kernel_regularizer=regularizers.l2(0.001)))\n","  model_cnn.add(Activation('relu'))\n","\n","  # Conv Layer 3\n","  model_cnn.add(Conv2D(64, (3, 3)))\n","  model_cnn.add(Activation('relu'))\n","  model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  # MLP\n","  model_cnn.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","  model_cnn.add(Dropout(0.5))\n","  model_cnn.add(Dense(64))\n","  model_cnn.add(Activation('relu'))\n","  #model_cnn.add(Dropout(0.5))\n","  model_cnn.add(Dense(4))\n","  model_cnn.add(Activation('softmax'))\n","\n","  \n","  return model_cnn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mdf2C1FABRrd"},"source":["STEPS_PER_EPOCH = TRAIN_DATA_LEN//BATCH_SIZE\n","lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n","  0.001,\n","  decay_steps=STEPS_PER_EPOCH*1000,\n","  decay_rate=1,\n","  staircase=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dTVq5SAnIQaN"},"source":["Train the model with dataset without augmentation"]},{"cell_type":"code","metadata":{"id":"W6ENtoexuWM-"},"source":["model_with_aug = get_model()  \n","model_with_aug.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.losses.CategoricalCrossentropy(),\n","              metrics=[tf.losses.CategoricalCrossentropy(name='CategoricalCrossentropy'), 'accuracy'])\n","\n","m_histories['No_augmentation_face'] = model_with_aug.fit(non_augmented_train_batches, epochs=250, validation_data=validation_batches, verbose=0, callbacks=get_callbacks('models/face_NoAug'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pUNTRe4uIWt2"},"source":["Train the model using dataset with augmentation"]},{"cell_type":"code","metadata":{"id":"qhXovE_2k4F7"},"source":["model_with_aug = get_model()  \n","model_with_aug.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.losses.CategoricalCrossentropy(),\n","              metrics=[tf.losses.CategoricalCrossentropy(name='CategoricalCrossentropy'), 'accuracy'])\n","\n","m_histories['With_augmentation_face'] = model_with_aug.fit(augmented_train_batches, epochs=250, validation_data=validation_batches, verbose=0, callbacks=get_callbacks('models/face_Aug'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7OuFdaNXIZZQ"},"source":["Plot the results"]},{"cell_type":"code","metadata":{"id":"CeuN6lg_56Bs"},"source":["plotter(m_histories, ylim=[0.0, 1.1], metric = 'CategoricalCrossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bz9XMW_tEJFN"},"source":["plotter(m_histories, ylim=[0.5, 1.1], metric = 'accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mNiYYJ6i1NY8"},"source":["**What other augmentation techniques are applicable to this task?**\n","\n","**What are some of the common augmentation techniques that are not applicable to this task?**"]},{"cell_type":"markdown","metadata":{"id":"E5EF3yvqELxp"},"source":["## Writing a dataloader\n","\n","Reading the data is a fundamental part of training neural networks and there are many tools provided with tensorflow and keras to do this. \n","\n","- The `tf.data` API enables you to build complex input pipelines from simple, reusable pieces. The tf.data API introduces a `tf.data.Dataset` abstraction that represents a sequence of elements, in which each element consists of one or more components. For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label. To create an input pipeline, you must start with a data source. For example, to construct a Dataset from data in memory, you can use `tf.data.Dataset.from_generator()` or `tf.data.Dataset.from_tensor_slices()`. Once you have a Dataset object, you can transform it into a new Dataset by chaining method calls on the `tf.data.Dataset` object. For example, you can apply per-element transformations such as `Dataset.map()`, and multi-element transformations such as `Dataset.batch()`. See the documentation for [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) for a complete list of transformations. You might have noticed by now that we have used this methods in the previous section. \n","\n","- The most common tool used for reading the data is [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) provided with keras. This `ImageDataGenerator` Generate batches of tensor image data with real-time data augmentation. If you wanted to do the last part on augmentation using this interface the code would look like below.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vwymg1P2MTBE"},"source":["### Using ImageDataGenerator"]},{"cell_type":"code","metadata":{"id":"wyvm8qO_LBI6"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Train data with augmentation\n","train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last', \n","                                   rotation_range=5, width_shift_range=0.15, \n","                                   height_shift_range=0.15)\n","val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n","\n","train_generator = train_datagen.flow_from_dataframe(\n","        dataframe=train_data_df,\n","        directory='./',\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        target_size=(32, 32),\n","        batch_size=BATCH_SIZE,\n","        color_mode=\"grayscale\",\n","        class_mode='categorical')\n","\n","validation_generator = val_datagen.flow_from_dataframe(\n","        dataframe=val_data_df,\n","        directory='./',\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        target_size=(32, 32),\n","        batch_size=BATCH_SIZE,\n","        color_mode=\"grayscale\",\n","        class_mode='categorical')\n","\n","m_histories = {}\n","model_with_aug_dg = get_model()  \n","model_with_aug_dg.compile(optimizer = tf.keras.optimizers.Adam(lr_schedule),\n","              loss=tf.losses.CategoricalCrossentropy(),\n","              metrics=[tf.losses.CategoricalCrossentropy(name='CategoricalCrossentropy'), 'categorical_accuracy'])\n","\n","m_histories['With_augm_face_datagen'] = model_with_aug_dg.fit(train_generator, epochs=250, validation_data=validation_generator, verbose=0, callbacks=get_callbacks('models/face_Aug_datagen'))\n","\n","plotter(m_histories, ylim=[0.0, 1.1], metric = 'CategoricalCrossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jly1CyBo67n"},"source":["plotter(m_histories, ylim=[0.0, 1.1], metric = 'categorical_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zM7P1d_GHmDd"},"source":["### Writing your own data generator\n","\n","There might be situations were the out of the box solutions provided with tensorflow are not applicable for you. What would you do in this case? \n","\n","We can always develop our own data loader. This can be done by inheriting the properties of `keras.utils.Sequence` so that we can leverage nice functionalities such as multiprocessing. Lets see how this is done.\n","\n","**This part of the Lab is base on the blog [A detailed example of how to use data generators with Keras](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) by Afshine Amidi and Shervine Amidi**"]},{"cell_type":"markdown","metadata":{"id":"GSscsUbMJsMy"},"source":["A data generator that is done by inheriting the properties of `keras.utils.Sequence`. needs to have four functions:\n","\n","- Initialization function of the class: `def __init__(self, )`\n","  - This function will set the global variables of the class. We set relevant information about the data, such as data dimensions, number of classes, batch size, or decide whether we want to shuffle our data at generation (If the shuffle parameter is set to True, we will get a new order of exploration at each pass). We also store important information such as labels and the list of IDs that we wish to generate at each pass.\n","- Function that returns the number of batches per epoch: `def __len__(self)`\n","  - Each call to the data loader requests a batch index between 0 and the total number of batches, where the total number of batches is specified in this method.\n","- Function evoked at the end of each epoch: `def on_epoch_end(self)`\n","  - Shuffling the order in which examples are fed to the classifier is helpful so that batches between epochs do not look alike. Doing so will eventually make our model more robust.\n","- A Function that returns the batch corresponding to a given index: `def __getitem__(self, index)` \n","\n","There might be other functions that supports the four above. The extra functions are not required but will improve the code readability.\n","\n","First let us write the code for reading the data for the above task. We are assuming that the data filenames and labels are provided to the dataloader at the start as a pandas dataframe. These fields will be read into the class at the initialization stage."]},{"cell_type":"code","metadata":{"id":"0gSJdTZMMmhL"},"source":["import tensorflow.keras as keras\n","from scipy.interpolate import interp1d\n","import numpy as np\n","from scipy.ndimage.interpolation import rotate, shift\n","from PIL import Image\n","\n","class DataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, data_frame, batch_size=8, dim=(32, 32, 1), n_classes=2, data_mean=0, data_std=1,  data_prefix='', shuffle=True, Augment=True):\n","        'Initialization'\n","        self.dim = dim  # Dimentions of the input\n","        self.batch_size = batch_size\n","        self.n_classes = n_classes  # Number of classes. This is for a classification task\n","        \n","        self.shuffle = shuffle  # Flag to shuffle data at the end of epoch\n","        self.Augment = Augment  # Falg to augmetn the data\n","\n","        # The data is input as a pandas dataframe, we need to read the relevent fields\n","        self.data_frame = data_frame\n","        self.image_label = data_frame['labels_num'].values.tolist()\n","        self.image_ids = np.arange(len(self.image_label)).tolist()\n","        self.data_prefix = data_prefix\n","        \n","        # Data normalization parameters\n","        self.data_mean = data_mean\n","        self.data_std = data_std\n","        \n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.image_ids) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data for the given index'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        \n","        # Find list of IDs\n","        data_ids_temp = [self.image_ids[k] for k in indexes]\n","        image_label_temp = [self.image_label[k] for k in indexes]\n","        \n","        # Generate data\n","        X, y = self.__data_generation(data_ids_temp, image_label_temp)\n","        \n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.image_ids))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","        \n","    # Support function\n","\n","    def __data_generation(self, data_ids_temp, image_label_temp):\n","        'Generates data containing batch_size samples' \n","\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim))\n","        y = np.empty((self.batch_size), dtype=int)\n","        \n","        # Generate data\n","        for i, ids in enumerate(data_ids_temp):\n","            \n","            X[i,] = self.__read_data_instance(data_ids_temp[i])\n","            y[i] = image_label_temp[i]\n","            \n","        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n","\n","\n","    def __read_data_instance(self, pid):\n","      # Read an image\n","      filepath = self.data_prefix + self.data_frame.iloc[pid]['image_path']\n","      \n","      data = Image.open(filepath)\n","      data = data.resize((32,32))\n","      data = np.asarray(data)\n","      data = np.expand_dims(data, axis=-1)\n","\n","      if self.Augment:\n","          rot = np.random.rand(1) < 0.5\n","          if rot:\n","              rot = np.random.randint(-10,10, size=1)\n","              data = rotate(data, angle=rot[0], reshape=False)\n","          \n","          shift_val = np.random.randint(-5, high=5, size=2, dtype=int).tolist() + [0,]\n","          data = shift(data, shift_val, order=0, mode='constant', cval=0.0, prefilter=False)\n","\n","      X = data\n","\n","      # Input normalization\n","      X = (X - self.data_mean)/self.data_std\n","      return X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvvtDmkV7GJ5"},"source":["Initialize the Data Generators i.e train and test."]},{"cell_type":"code","metadata":{"id":"t_KxI1ymR-MB"},"source":["data_mean = 0.\n","data_std = 255.0\n","prefix=''\n","training_generator = DataGenerator(train_data_df, batch_size=BATCH_SIZE, data_mean=data_mean, data_std=data_std, n_classes=4, Augment=True, data_prefix=prefix)\n","validation_generator = DataGenerator(val_data_df, batch_size=BATCH_SIZE, data_mean=data_mean, data_std=data_std, n_classes=4, Augment=False, data_prefix=prefix)\n","\n","nEpochs = 250"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EL9F5Sea7Oon"},"source":["It is good practice to plot the data generated by the code to see if everything is working as expected. "]},{"cell_type":"code","metadata":{"id":"jXXDk9zwTDTa"},"source":["print(training_generator.__len__())\n","\n","for x,y in training_generator.__iter__():\n","  print(x.shape, y.shape)\n","\n","#   plt.imshow(x[0,:,:,0], cmap='gray')\n","#   plt.pause(.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jh1wv_FX7n-O"},"source":["Train the model and plot results."]},{"cell_type":"code","metadata":{"id":"r3rWX30Oah2P"},"source":["model2 = get_model()\n","model2.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.losses.CategoricalCrossentropy(),\n","              metrics=[tf.losses.CategoricalCrossentropy(name='CategoricalCrossentropy'), 'categorical_accuracy'])\n","\n","m_histories = {}\n","m_histories['With_augm_face_datagen'] = model2.fit(training_generator, epochs=250, validation_data=validation_generator, verbose=0, callbacks=get_callbacks('models/face_Aug_datagen'))\n","\n","plotter(m_histories, ylim=[0.0, 1.1], metric = 'CategoricalCrossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qM9BuKYjD0Z"},"source":["plotter(m_histories, ylim=[0.0, 1.1], metric = 'categorical_accuracy')"],"execution_count":null,"outputs":[]}]}